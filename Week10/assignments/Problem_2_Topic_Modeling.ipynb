{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a98c739c45025e75b7a8a39168517825",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ → _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ac95214f13943d2ae73fde6293adefd",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 2. Topic Modeling.\n",
    "\n",
    "In this problem, we use the [genism](https://radimrehurek.com/gensim/) library to create a topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6de40ca1fbf81d26129075470115ac59",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "147cfb9203151b554e3988bb6b83ad9b",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Suppose we are given some sample documents as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5bc6713a2313aaac560e5585f845348f",
     "grade": false,
     "grade_id": "doc_set",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "095ed02651ccc624def64ef06cd06800",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To generate a topic model, first we need to perform some basic text processing. In natural language processing, the following steps are commonly used:\n",
    "\n",
    "- Tokenizing: breaking a text into its elements.\n",
    "- Stopping: removing meaningless words.\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "- Write a function named `tokenize` that takes **one** document (a string, e.g. `doc_a` or `doc_b`, *not* `doc_set`) and returns a list of tokens.\n",
    "- The function also takes a second argument, `stop_words`, a list of strings.\n",
    "- All tokens in the returned list should be lowercase.\n",
    "- For example, when we run\n",
    "```python\n",
    ">>> doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    ">>> stop_words = \"for a of the and to in on an but at\".split()\n",
    ">>> print(tokenize(doc_b, stop_words))\n",
    "```\n",
    "we should get\n",
    "```\n",
    "['my', 'mother', 'spends', 'lot', 'time', 'driving', 'my', 'brother', 'around', 'baseball', 'practice.']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "38480305536f1d997f1e530422cf1501",
     "grade": false,
     "grade_id": "tokenize_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(doc, stop_words):\n",
    "    \"\"\"\n",
    "    Tokenizes a string, removing 'stop_words'.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    doc: A string.\n",
    "    stop_words: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "451903c9e90298f21b3f01d7568dbb58",
     "grade": false,
     "grade_id": "tokenize_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stop_words = \"for a of the and to in on an but at\".split()\n",
    "tokens_a = tokenize(doc_a, stop_words)\n",
    "print(tokens_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c01cd77331580e836924aaccd468bae4",
     "grade": true,
     "grade_id": "tokenize_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def test_doc_tokens(doc, tokens):\n",
    "    assert_is_instance(tokens, list)\n",
    "    assert_true(all(isinstance(t, str) for t in tokens))\n",
    "    assert_true(all(t in doc.lower() for t in tokens))\n",
    "    assert_true(all(\" \" not in t for t in tokens))\n",
    "    assert_true(all(t not in stop_words for t in tokens))\n",
    "    \n",
    "for doc in doc_set:\n",
    "    tokens = tokenize(doc, stop_words)\n",
    "    test_doc_tokens(doc, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2fa540c722ce17f659bc70e25dfd93c",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note that our `tokenize` function tokenizes only *one* document, but we want to tokenize *all* documents in `doc_set`, because the `corpora.Dictionary()` function accepts a list of lists, one list for each of our documents. (See the [Introduction to Topic Modeling notebook](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week10/notebooks/intro2nlp-tm.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9f531ca564969ee12d04580030884b70",
     "grade": false,
     "grade_id": "print_texts",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "texts = [tokenize(d, stop_words) for d in doc_set]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a48f6e26715783989c28ba9528bfe9db",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(Note that we have taken a slightly different approach than the approach used in the [Introduction to Topic Modeling notebook](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week10/notebooks/intro2nlp-tm.ipynb), where we used nested list comprehensions. Another difference is that we used only tokens that appear more than once, but here we use all tokens, even those that appear only once.)\n",
    "\n",
    "Now that we have a list of lists for each document, we are ready to use `corpora.Dictionary` to contstruct a [document-term matrix](https://en.wikipedia.org/wiki/Document-term_matrix). The `Dictionary()` function goes through each text and assigns a unique integer ID to each unique token. At the same time, it also counts how frequently each term appears within each document. The result is a mapping (i.e., a dictionary) of each words to its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0e062a459520121e2b89862c6a40376a",
     "grade": false,
     "grade_id": "print_dictionary",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3297c3aa80ddebdb622eae335f03fe3c",
     "grade": false,
     "grade_id": "print_brocolli",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(dictionary.token2id[\"brocolli\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "06ce44e2a1f080d6de4d0c7406036b4d",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The `doc2bow()` method converts dictionary into a [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model). The result is a corpus: a list of lists, where each list is a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9f9b22a63008cac76ed03958235205d8",
     "grade": false,
     "grade_id": "print_corpus",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c4fe70974ca902c97fa4282d5d3b776",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For example, `corpus[0]` represents our first document, `doc_a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d72eca36c817fd1201e6d0328e1f6075",
     "grade": false,
     "grade_id": "print_corpus_0",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1c6e10d5982ed22c576d86a9f1b67961",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The tuples are of the form (term ID, term frequency), so if\n",
    "```python\n",
    ">>> print(dictionary.token2id[\"brocolli\"])\n",
    "```\n",
    "says brocolli’s ID is 0 (this ID will be different every time you run the notebook), then the tuple `(0, 2)` indicates that brocolli appeared twice in `doc_a`.\n",
    "\n",
    "With the document term matrix (`corpus`) we can construct a topic model. In the following code cell, we use latent Dirichlet allocation (LDA). To learn more about LDA, see for example [Topic Modeling and Digital Humanities](http://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0aac65bb6eaa86cbf4bb6b5993e1895f",
     "grade": false,
     "grade_id": "print_lda",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, passes=20)\n",
    "print(lda_model.print_topics(num_topics=2, num_words=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d016358011a2b9b146ffbdd8cd55a35f",
     "grade": false,
     "grade_id": "markdown_8",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "When I ran this,\n",
    "```python\n",
    ">>> lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, passes=20)\n",
    ">>> print(lda_model.print_topics(num_topics=2, num_words=3))\n",
    "```\n",
    "I got\n",
    "```\n",
    "[(0, '0.078*good + 0.055*brocolli + 0.055*is'), (1, '0.073*my + 0.041*brother + 0.040*mother')]\n",
    "```\n",
    "\n",
    "(The output will be slightly different every time you run the notebook.)\n",
    "\n",
    "We have two topics separated by a comma. Each topic has three words that are most likely to appear in that topic. Usually, topic modeling requires a large set of documents, but our model looks reasonable, even with our small docuement set: \"good\" and \"brocolli\" together make sense; the second topic, \"brother\" and \"mother\", also seems reasonable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
